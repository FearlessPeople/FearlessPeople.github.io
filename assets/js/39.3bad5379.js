(window.webpackJsonp=window.webpackJsonp||[]).push([[39],{480:function(e,a,r){"use strict";r.r(a);var t=r(10),s=Object(t.a)({},(function(){var e=this,a=e.$createElement,r=e._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h2",{attrs:{id:"错误日志"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#错误日志"}},[e._v("#")]),e._v(" 错误日志")]),e._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("19/05/22 09:32:59 WARN scheduler.TaskSetManager: Lost task 675.0 in stage 7.0 (TID 2242, hi-prod-10.hillinsight.com): java.io.IOException: java.io.IOException: java.lang.RuntimeException: java.io.EOFException: Read past end of RLE integer from compressed stream Stream for column 1 kind LENGTH position: 4332 length: 4332 range: 0 offset: 519193 limit: 519193 range 0 = 0 to 4332 uncompressed: 4 to 4\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:226)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.next(HadoopShimsSecure.java:136)\n\tat org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:246)\n\tat org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:208)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:29)\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:93)\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)\n\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:163)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: java.lang.RuntimeException: java.io.EOFException: Read past end of RLE integer from compressed stream Stream for column 1 kind LENGTH position: 4332 length: 4332 range: 0 offset: 519193 limit: 519193 range 0 = 0 to 4332 uncompressed: 4 to 4\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)\n\tat org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:355)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:105)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:41)\n\tat org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:116)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:224)\n\t... 16 more\nCaused by: java.lang.RuntimeException: java.io.EOFException: Read past end of RLE integer from compressed stream Stream for column 1 kind LENGTH position: 4332 length: 4332 range: 0 offset: 519193 limit: 519193 range 0 = 0 to 4332 uncompressed: 4 to 4\n\tat org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat$VectorizedOrcRecordReader.next(VectorizedOrcInputFormat.java:95)\n\tat org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat$VectorizedOrcRecordReader.next(VectorizedOrcInputFormat.java:49)\n\tat org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:350)\n\t... 20 more\nCaused by: java.io.EOFException: Read past end of RLE integer from compressed stream Stream for column 1 kind LENGTH position: 4332 length: 4332 range: 0 offset: 519193 limit: 519193 range 0 = 0 to 4332 uncompressed: 4 to 4\n\tat org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.readValues(RunLengthIntegerReaderV2.java:56)\n\tat org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.next(RunLengthIntegerReaderV2.java:302)\n\tat org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.nextVector(RunLengthIntegerReaderV2.java:346)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl$BytesColumnVectorUtil.commonReadByteArrays(RecordReaderImpl.java:1365)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl$BytesColumnVectorUtil.readOrcByteArrays(RecordReaderImpl.java:1399)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl$StringDirectTreeReader.nextVector(RecordReaderImpl.java:1508)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl$StringTreeReader.nextVector(RecordReaderImpl.java:1347)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl$StructTreeReader.nextVector(RecordReaderImpl.java:1902)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.nextBatch(RecordReaderImpl.java:3191)\n\tat org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat$VectorizedOrcRecordReader.next(VectorizedOrcInputFormat.java:93)\n\t... 22 more\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br"),r("span",{staticClass:"line-number"},[e._v("2")]),r("br"),r("span",{staticClass:"line-number"},[e._v("3")]),r("br"),r("span",{staticClass:"line-number"},[e._v("4")]),r("br"),r("span",{staticClass:"line-number"},[e._v("5")]),r("br"),r("span",{staticClass:"line-number"},[e._v("6")]),r("br"),r("span",{staticClass:"line-number"},[e._v("7")]),r("br"),r("span",{staticClass:"line-number"},[e._v("8")]),r("br"),r("span",{staticClass:"line-number"},[e._v("9")]),r("br"),r("span",{staticClass:"line-number"},[e._v("10")]),r("br"),r("span",{staticClass:"line-number"},[e._v("11")]),r("br"),r("span",{staticClass:"line-number"},[e._v("12")]),r("br"),r("span",{staticClass:"line-number"},[e._v("13")]),r("br"),r("span",{staticClass:"line-number"},[e._v("14")]),r("br"),r("span",{staticClass:"line-number"},[e._v("15")]),r("br"),r("span",{staticClass:"line-number"},[e._v("16")]),r("br"),r("span",{staticClass:"line-number"},[e._v("17")]),r("br"),r("span",{staticClass:"line-number"},[e._v("18")]),r("br"),r("span",{staticClass:"line-number"},[e._v("19")]),r("br"),r("span",{staticClass:"line-number"},[e._v("20")]),r("br"),r("span",{staticClass:"line-number"},[e._v("21")]),r("br"),r("span",{staticClass:"line-number"},[e._v("22")]),r("br"),r("span",{staticClass:"line-number"},[e._v("23")]),r("br"),r("span",{staticClass:"line-number"},[e._v("24")]),r("br"),r("span",{staticClass:"line-number"},[e._v("25")]),r("br"),r("span",{staticClass:"line-number"},[e._v("26")]),r("br"),r("span",{staticClass:"line-number"},[e._v("27")]),r("br"),r("span",{staticClass:"line-number"},[e._v("28")]),r("br"),r("span",{staticClass:"line-number"},[e._v("29")]),r("br"),r("span",{staticClass:"line-number"},[e._v("30")]),r("br"),r("span",{staticClass:"line-number"},[e._v("31")]),r("br"),r("span",{staticClass:"line-number"},[e._v("32")]),r("br"),r("span",{staticClass:"line-number"},[e._v("33")]),r("br"),r("span",{staticClass:"line-number"},[e._v("34")]),r("br"),r("span",{staticClass:"line-number"},[e._v("35")]),r("br"),r("span",{staticClass:"line-number"},[e._v("36")]),r("br"),r("span",{staticClass:"line-number"},[e._v("37")]),r("br"),r("span",{staticClass:"line-number"},[e._v("38")]),r("br"),r("span",{staticClass:"line-number"},[e._v("39")]),r("br"),r("span",{staticClass:"line-number"},[e._v("40")]),r("br"),r("span",{staticClass:"line-number"},[e._v("41")]),r("br"),r("span",{staticClass:"line-number"},[e._v("42")]),r("br"),r("span",{staticClass:"line-number"},[e._v("43")]),r("br"),r("span",{staticClass:"line-number"},[e._v("44")]),r("br"),r("span",{staticClass:"line-number"},[e._v("45")]),r("br"),r("span",{staticClass:"line-number"},[e._v("46")]),r("br")])]),r("h2",{attrs:{id:"问题原因"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#问题原因"}},[e._v("#")]),e._v(" 问题原因")]),e._v(" "),r("p",[e._v("此乃ORC文件格式的Bug，升级Hive版本或者换成RCFile等其他格式即可")]),e._v(" "),r("p",[e._v("网上也有说是使用小文件合并的问题，算是hive的一个bug吧")]),e._v(" "),r("p",[e._v("Bug链接："),r("a",{attrs:{href:"https://issues.apache.org/jira/browse/HIVE-10916",target:"_blank",rel:"noopener noreferrer"}},[e._v("HIVE-10916"),r("OutboundLink")],1)]),e._v(" "),r("p",[e._v("使用以下参数将会出现这些问题：")]),e._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("set hive.merge.mapfiles=true;\nset hive.merge.mapredfiles=true;\nset hive.merge.smallfiles.avgsize=256000000;\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br"),r("span",{staticClass:"line-number"},[e._v("2")]),r("br"),r("span",{staticClass:"line-number"},[e._v("3")]),r("br")])]),r("h2",{attrs:{id:"解决方案"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[e._v("#")]),e._v(" 解决方案：")]),e._v(" "),r("h3",{attrs:{id:"_1-升级hive版本-推荐"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-升级hive版本-推荐"}},[e._v("#")]),e._v(" 1. 升级hive版本（推荐）")]),e._v(" "),r("p",[e._v("升级hive到hive 1.3.x以上版本")]),e._v(" "),r("h3",{attrs:{id:"_2-尝试不做小文件合并"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-尝试不做小文件合并"}},[e._v("#")]),e._v(" 2. 尝试不做小文件合并")]),e._v(" "),r("p",[e._v("关闭小文件合并参数")]),e._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("set hive.merge.mapredfiles = false;\nset hive.merge.mapfiles = false;\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br"),r("span",{staticClass:"line-number"},[e._v("2")]),r("br")])]),r("h3",{attrs:{id:"_3-改为其他格式rcfile"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-改为其他格式rcfile"}},[e._v("#")]),e._v(" 3. 改为其他格式rcfile")]),e._v(" "),r("div",{staticClass:"language-sql line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-sql"}},[r("code",[r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("create")]),e._v(" "),r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("table")]),e._v(" xxx "),r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("as")]),e._v(" store "),r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("as")]),e._v(" rcfile\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br")])])])}),[],!1,null,null,null);a.default=s.exports}}]);
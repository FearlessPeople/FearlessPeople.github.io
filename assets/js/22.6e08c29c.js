(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{461:function(e,t,a){"use strict";a.r(t);var n=a(10),r=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#介绍"}},[e._v("#")]),e._v(" 介绍")]),e._v(" "),a("p",[e._v("Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的日志收集系统。同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力 。Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统），支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。\nFlume是事件(event)驱动。一般情况下，web server触发事件，产生流 数据;Agent处理事件，传输数据;最终数据存储在HDFS中。\nFlume以agent为最小独立运行单位，1个agent为1个JVM。")]),e._v(" "),a("p",[e._v("现在是Apache的顶级项目之一"),a("a",{attrs:{href:"http://flume.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://flume.apache.org/"),a("OutboundLink")],1),e._v("\n各版本下载地址："),a("a",{attrs:{href:"http://www-us.apache.org/dist/flume/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www-us.apache.org/dist/flume/"),a("OutboundLink")],1),e._v("\n当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。")]),e._v(" "),a("ol",[a("li",[e._v("Flume-og采用了多Master的方式。为了保证配置数据的一致性，Flume引入了ZooKeeper，用于保存配置数据，ZooKeeper本身可保证配置数据的一致性和高可用，另外，在配置数据发生变化时，ZooKeeper可以通知Flume Master节点。Flume Master间使用gossip协议同步数据。")]),e._v(" "),a("li",[e._v("Flume-ng最明显的改动就是取消了集中管理配置的 Master 和 Zookeeper，变为一个纯粹的传输工具。Flume-ng另一个主要的不同点是读入数据和写出数据现在由不同的工作线程处理（称为 Runner）。 在 Flume-og 中，读入线程同样做写出工作（除了故障重试）。如果写出慢的话（不是完全失败），它将阻塞 Flume 接收数据的能力。这种异步的设计使读入线程可以顺畅的工作而无需关注下游的任何问题。")])]),e._v(" "),a("h2",{attrs:{id:"flume架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flume架构"}},[e._v("#")]),e._v(" Flume架构")]),e._v(" "),a("p",[e._v("Flume-ng架构图")]),e._v(" "),a("p",[a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4ffkyzgrj30u60awjtp.jpg",alt:""}})]),e._v(" "),a("p",[e._v("flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。\nflume之所以这么神奇，是源于它自身的一个设计，这个设计就是agent，agent本身是一个java进程，运行在日志收集节点—所谓日志收集节点就是服务器节点。\nagent里面包含3个核心的组件：source—->channel—–>sink,类似生产者、仓库、消费者的架构。\n"),a("strong",[e._v("source")]),e._v("：source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据,包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy、自定义。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fi34y0nj31d60sa451.jpg",alt:"img"}}),e._v(" "),a("strong",[e._v("channel")]),e._v("：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在memory、jdbc、file等等。注意：只有在sink将channel中的数据成功发送出去之后，channel才会将临时数据进行删除，这种机制保证了数据传输的可靠性与安全性。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fivlr1qj31de0gyn0f.jpg",alt:"img"}}),e._v(" "),a("strong",[e._v("sink")]),e._v("：sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fjbs3jwj31dk0qewjq.jpg",alt:"img"}})]),e._v(" "),a("h2",{attrs:{id:"flume架构的几个核心概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flume架构的几个核心概念"}},[e._v("#")]),e._v(" Flume架构的几个核心概念")]),e._v(" "),a("p",[a("strong",[e._v("Event")]),e._v("\n在Flume的整个数据传输过程中，流动的是event，即事务保证是在event级别进行的。"),a("strong",[e._v("那么什么是event呢？")]),e._v("—–event将传输的数据进行封装，是flume传输数据的基本单位，如果是文本文件，通常是一行记录，event也是事务的基本单位。event从source，流向channel，再到sink，本身为一个字节数组，并可携带headers(头信息)信息。event代表着一个数据的最小完整单元，从外部数据源来，向外部的目的地去。\n为了方便大家理解，给出一张event的数据流向图：\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fk991pmj30v00fimzm.jpg",alt:"img"}}),e._v("\n一个完整的event包括：event headers、event body、event信息(即文本文件中的单行记录)，如下所以：\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fkg47a5j31go02hgls.jpg",alt:"这里写图片描述"}}),e._v("\n其中event信息就是flume收集到的日记记录。")]),e._v(" "),a("h2",{attrs:{id:"flume的广义用法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flume的广义用法"}},[e._v("#")]),e._v(" Flume的广义用法")]),e._v(" "),a("p",[e._v("Flume之所以这么神奇—-其原因也在于flume可以支持多级flume的agent，即flume可以前后相继，例如sink可以将数据写到下一个agent的source中，这样的话就可以连成串了，可以整体处理了。flume还支持扇入(fan-in)、扇出(fan-out)。所谓扇入就是source可以接受多个输入，所谓扇出就是sink可以将数据输出多个目的地destination中。")]),e._v(" "),a("ol",[a("li",[e._v("如下图：sink将数据输出到HDFS,JMS之后，同时又输出到另一个Agent的Source中\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fkiiv5aj30fe08haaw.jpg",alt:"这里写图片描述"}})]),e._v(" "),a("li",[e._v("如下图：可以将多个Agent的数据聚集到同一个Agent中，然后再输出到HDFS中。\n这种情况应用的场景比较多，比如要收集Web网站的用户行为日志，Web网站为了可用性使用的负载均衡的集群模式，每个节点都产生用户行为日志，可以为每个节点都配置一个Agent来单独收集日志数据，然后多个Agent将数据最终汇聚到一个用来存储数据存储系统，如HDFS上。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fkpb9dej30o80ss7a8.jpg",alt:"img"}})])]),e._v(" "),a("h2",{attrs:{id:"flume-og和flume-ng的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flume-og和flume-ng的区别"}},[e._v("#")]),e._v(" Flume OG和Flume NG的区别")]),e._v(" "),a("h3",{attrs:{id:"flum-og-的特点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flum-og-的特点"}},[e._v("#")]),e._v(" FLUM OG 的特点")]),e._v(" "),a("p",[e._v("FLUM OG 有三种角色的节点，代理节点（agent）、收集节点（collector）、主节点（master）。\nagent 从各个数据源收集日志数据，将收集到的数据集中到 collector，然后由收集节点汇总存入 hdfs。master 负责管理 agent，collector 的活动。\nagent、collector 都称为 node，node 的角色根据配置的不同分为 logical node（逻辑节点）、physical node（物理节点）。对 logical nodes 和 physical nodes 的区分、配置、使用一直以来都是使用者最头疼的地方。\nagent、collector 由 source、sink 组成，代表在当前节点数据是从 source 传送到 sink。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fklsm3pj30z80o0jz2.jpg",alt:"img"}})]),e._v(" "),a("h3",{attrs:{id:"flum-ng-的特点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flum-ng-的特点"}},[e._v("#")]),e._v(" FLUM NG 的特点")]),e._v(" "),a("p",[e._v("NG 只有一种角色的节点：代理节点（agent）。\n没有 collector、master 节点。这是核心组件最核心的变化。\n去除了 physical nodes、logical nodes 的概念和相关内容。\nagent 节点的组成也发生了变化。如图 4，NG agent 由 source、sink、channel 组成。\n"),a("img",{attrs:{src:"/img/BigData/Flume/0069RVTdgy1fu4fkxsx06j30zw0pen94.jpg",alt:"img"}})]),e._v(" "),a("h3",{attrs:{id:"改进"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#改进"}},[e._v("#")]),e._v(" 改进")]),e._v(" "),a("p",[e._v("大规模的调整，核心组件的数目由 7 删减到 4。由于 Flume 的使用涉及到众多因素，如 avro、thrift、hdfs、jdbc、zookeeper 等，而这些组件和 Flume 的整合都需要关联到所有组件。所以核心组件的改革对整个 Flume 的使用影响深远：\n大大降低了对用户的要求，如核心组件的变化使得 Flume 的稳定使用不再依赖 zookeeper，用户无需去搭建 zookeeper 集群；另外用户也不再纠结于 OG 中的模糊概念（尤其是 physical nodes、logical nodes，agent、collector）。\n有利于 Flume 和其他技术、hadoop 周边组件的整合，比如在 NG 版本中，Flume 轻松实现了和 jdbc、hbase 的集成。\n将 OG 版本中复杂、大规模、不稳定的标签移除，Flume 实现了向灵活、轻便的转变，而且在功能上更加强大、可扩展性更高，这一点主要表现在用户使用 Flume 搭建日志收集集群的过程中。")]),e._v(" "),a("h2",{attrs:{id:"参考"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[e._v("#")]),e._v(" 参考")]),e._v(" "),a("p",[a("a",{attrs:{href:"http://flume.apache.org/FlumeUserGuide.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://flume.apache.org/FlumeUserGuide.html"),a("OutboundLink")],1),e._v(" "),a("a",{attrs:{href:"http://shiyanjun.cn/archives/915.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://shiyanjun.cn/archives/915.html"),a("OutboundLink")],1),e._v(" "),a("a",{attrs:{href:"http://blog.csdn.net/a2011480169/article/details/51544664",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://blog.csdn.net/a2011480169/article/details/51544664"),a("OutboundLink")],1),e._v(" "),a("a",{attrs:{href:"http://blog.csdn.net/zhaodedong/article/details/52541688",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://blog.csdn.net/zhaodedong/article/details/52541688"),a("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=r.exports}}]);